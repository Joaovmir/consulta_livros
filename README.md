# Projeto: API de Consulta de Livros

Este projeto consiste em duas partes principais que trabalham em conjunto:

1.  **Web Scraper**: Um script em Python (`scripts/webscraping_livros.py`) que utiliza Selenium para extrair dados de livros do site [Books to Scrape](http://books.toscrape.com). Os dados recolhidos sÃ£o guardados num ficheiro CSV.
2.  **API REST**: Uma API (`api/main.py`) construÃ­da com FastAPI que lÃª o ficheiro CSV e disponibiliza os dados atravÃ©s de vÃ¡rios endpoints, permitindo consultas, filtros e a visualizaÃ§Ã£o de estatÃ­sticas.

-----

## ğŸ“‚ Estrutura de Pastas

O projeto estÃ¡ organizado da seguinte forma para manter o cÃ³digo limpo e modular:

```
/CONSULTA_LIVROS/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # CÃ³digo principal da API FastAPI
â”‚   â”œâ”€â”€ auth.py              # LÃ³gica de autenticaÃ§Ã£o com JWT
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ db.py                # ConexÃ£o com SQLite usando SQLAlchemy
â”‚   â”œâ”€â”€ init_db.py           # CriaÃ§Ã£o da tabela users e usuÃ¡rio admin
â”‚   â””â”€â”€ users.db             # Arquivo do banco de dados SQLite
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ user.py              # Modelo SQLAlchemy para User
â”‚   â”œâ”€â”€ book_models.py       # Modelos Pydantic para livros e estatÃ­sticas
â”‚   â””â”€â”€ health.py            # Modelo Pydantic para o health check
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ webscraping_livros.py  # Script de scraping de livros
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ info_livros.csv      # Arquivo CSV com os dados extraÃ­dos do site
â”‚
â”œâ”€â”€ requirements.txt         # Lista de dependÃªncias do projeto
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â””â”€â”€ .gitignore               # Arquivos/pastas ignoradas pelo Git
|
... (outros ficheiros de configuraÃ§Ã£o)
```

-----

## âš™ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de que tem o **Python 3.10+** instalado. Depois, abra o seu terminal na pasta raiz do projeto (`/CONSULTA_LIVROS/`) e instale todas as bibliotecas necessÃ¡rias a partir do ficheiro `requirements.txt`.

```bash
pip install -r requirements.txt
```

-----

## ğŸš€ Como Executar o Projeto

Siga estes passos na ordem correta. **Execute todos os comandos a partir da pasta raiz do projeto (`/CONSULTA_LIVROS/`)**.

### **(Opcional) Passo 1: Extrair os Dados**

Caso ainda nÃ£o tenha o arquivo de dados, execute o scraping. O scraping sÃ³ pode ser executado via endpoint da API, pois implementamos autenticaÃ§Ã£o para proteger a rota, e requer um **usuÃ¡rio autenticado com perfil admin**.

1. Inicie a API:
```bash
uvicorn api.main:app --reload
```

2. FaÃ§a login (via Postman):
- MÃ©todo: POST
- URL: http://127.0.0.1:8000/api/v1/auth/login
- Body (x-www-form-urlencoded):
  - username: admin
  - password: admin123

Copie o access_token da resposta.

3. FaÃ§a a chamada para o endpoint de scraping:
- MÃ©todo: POST
- URL: http://127.0.0.1:8000/api/v1/scraping/trigger
  - Headers:
    - Authorization: Bearer <cole_seu_token_aqui>

Isso irÃ¡:

1.  Solicitar no terminal se "Deseja abrir o navegador visivelmente? (s/n)"
2.  Iniciar um navegador Chrome em segundo plano (modo *headless*).
3.  Navegar pelo site `books.toscrape.com` e recolher os dados.
4.  Criar a pasta `data/` (se nÃ£o existir) 
5.  Solicitar "Escreva um nome para o arquivo de dados (apenas o nome, sem o formato .csv):"
6.  Informe o nome `info_livros`.
7.  Guardar tudo no ficheiro `data/info_livros.csv`.

Aguarde atÃ© que a mensagem `âœ… Arquivo salvo com sucesso.` apareÃ§a no terminal.

### **Passo 2: Iniciar a API**

Caso nÃ£o tenha iniciado a API mas jÃ¡ tem o ficheiro `info_livros.csv` jÃ¡ criado, pode iniciar o servidor da API.

```bash
uvicorn api.main:app --reload
```

  * `api.main`: Indica ao Uvicorn para procurar o objeto `app` dentro do ficheiro `main.py` que estÃ¡ na pasta `api/`.
  * `--reload`: Reinicia o servidor automaticamente sempre que fizer alteraÃ§Ãµes no cÃ³digo.

O terminal deverÃ¡ mostrar uma mensagem a indicar que o servidor estÃ¡ a funcionar:

```
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
```

### **Passo 3: Ver a DocumentaÃ§Ã£o e Usar a API**

Agora que o servidor estÃ¡ ativo, abra o seu navegador de internet e aceda ao seguinte endereÃ§o:

[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

IrÃ¡ ver a documentaÃ§Ã£o interativa do **Swagger UI**, onde pode explorar e testar todos os endpoints da sua API diretamente no navegador.
